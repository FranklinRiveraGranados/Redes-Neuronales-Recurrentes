{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_LSTM_a_nivel_caracter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S7K8Ubm3LJU"
      },
      "source": [
        "###Una RNN LSTM a nivel de caracter\n",
        "Vamos a crear una LSTM a nivel de caracter, este modelo será entrenado caracter a caracter y generará un nuevo texto.\n",
        "\n",
        "Esta red esta basada en Andrej Karpathy's RNNs e implementada en Torch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI0gPGov23fY"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DAFW2k_5woO"
      },
      "source": [
        "####Cargamos nuestra data\n",
        "Vamos a cargar nuestro archivo de texto y convertirlo en enteros para que nuestra red LSMT la use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW6m9YLv5u6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8aa11e-1460-465d-c6f6-1e8533c37a48"
      },
      "source": [
        "#Abrimos la data y leemos el archivo\n",
        "with open('archivo.txt','r') as f:\n",
        "  text = f.read()\n",
        "len(text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "691699"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBdMq3fM9l15"
      },
      "source": [
        "Veamos lor primeros 250 caracteres del texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "KGum4aKZ6JiK",
        "outputId": "9f029d23-a84b-4b0b-b98a-8049f7fc10cf"
      },
      "source": [
        "text[:250]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Como ya se ha indicado, las veinte secuencias narrativas siguen por lo común el orden cronológico,\\npero una importante excepción tiene lugar precisamente en el relato de los acontecimientos que\\nllevaron a la fundación de Macondo, que se encuentra en '"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ki-ZUzF9ueQ"
      },
      "source": [
        "###Tokenización\n",
        "Vamos a crear dos diccionarios para convertir los caracteres en enteros, al hacer esto será más fácil usarlo para la entrada de nuestra red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NYaGv_-9shF"
      },
      "source": [
        "#Codificamos nuestro texto y mapeamos cada caracter a un entero y viceversa\n",
        "\n",
        "#Vamos a crear dos diccionarios:\n",
        "# 1. int_a_char, mapea enteros a caracteres\n",
        "# 2. char_a_int, mapea caracteres a un único entero\n",
        "\n",
        "caracteres = tuple(set(text))\n",
        "int_a_char = dict(enumerate(caracteres))\n",
        "char_a_int = {ch: ii for ii, ch in int_a_char.items()}\n",
        "\n",
        "#codificamos el texto\n",
        "encoded = np.array([char_a_int[ch] for ch in text])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJTUeFb3OxxN"
      },
      "source": [
        "Ahora vemos el mismo texto de ejercicio codificado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El0rBIGV-5D9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81da1b07-de4b-4755-d902-f490a6d08e2b"
      },
      "source": [
        "encoded[:250]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([50,  4, 58,  4, 30, 48, 40, 30, 15, 42, 30, 39, 40, 30, 34, 56, 25,\n",
              "       34, 24, 40, 25,  4, 17, 30, 11, 40, 15, 30, 31, 42, 34, 56, 12, 42,\n",
              "       30, 15, 42, 24, 47, 42, 56, 24, 34, 40, 15, 30, 56, 40, 28, 28, 40,\n",
              "       12, 34, 31, 40, 15, 30, 15, 34, 22, 47, 42, 56, 30, 53,  4, 28, 30,\n",
              "       11,  4, 30, 24,  4, 58, 57, 56, 30, 42, 11, 30,  4, 28, 25, 42, 56,\n",
              "       30, 24, 28,  4, 56,  4, 11, 37, 22, 34, 24,  4, 17, 13, 53, 42, 28,\n",
              "        4, 30, 47, 56, 40, 30, 34, 58, 53,  4, 28, 12, 40, 56, 12, 42, 30,\n",
              "       42, 43, 24, 42, 53, 24, 34, 37, 56, 30, 12, 34, 42, 56, 42, 30, 11,\n",
              "       47, 22, 40, 28, 30, 53, 28, 42, 24, 34, 15, 40, 58, 42, 56, 12, 42,\n",
              "       30, 42, 56, 30, 42, 11, 30, 28, 42, 11, 40, 12,  4, 30, 25, 42, 30,\n",
              "       11,  4, 15, 30, 40, 24,  4, 56, 12, 42, 24, 34, 58, 34, 42, 56, 12,\n",
              "        4, 15, 30,  1, 47, 42, 13, 11, 11, 42, 31, 40, 28,  4, 56, 30, 40,\n",
              "       30, 11, 40, 30, 54, 47, 56, 25, 40, 24, 34, 37, 56, 30, 25, 42, 30,\n",
              "        2, 40, 24,  4, 56, 25,  4, 17, 30,  1, 47, 42, 30, 15, 42, 30, 42,\n",
              "       56, 24, 47, 42, 56, 12, 28, 40, 30, 42, 56, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa30YEk1fIPv"
      },
      "source": [
        "###Procesar la data\n",
        "Las redes neuronales solo aceptan números, entonces vamos a tener que hacer que nuestros datos sean números y podemos hacer eso con **one-hot encoded** que significa que cada carácter es convertido a un entero y luego en una columna de vectores que para el entero que correponde tendría un 1 y el resto lleno de 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4GVcqBDO3Hb"
      },
      "source": [
        "def one_hot_encode(arr,n_labels):\n",
        "  #Iniciamos el arreglo de codificación\n",
        "  one_hot = np.zeros((arr.size,n_labels),dtype=np.float32)\n",
        "\n",
        "  #LLenamos apropiadamente con uno\n",
        "  one_hot[np.arange(one_hot.shape[0]),arr.flatten()]=1.\n",
        "\n",
        "  #Finalmente hacemos un reshape\n",
        "  one_hot = one_hot.reshape((*arr.shape,n_labels))\n",
        "\n",
        "  return one_hot"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM4DfN7mf4m_",
        "outputId": "06ac912c-b80f-4c9a-9ecb-c8d2afff1c86"
      },
      "source": [
        "#Verificamos que la función es correcta\n",
        "test_seq = np.array([[3,5,1]])\n",
        "one_hot = one_hot_encode(test_seq,8)\n",
        "\n",
        "print(one_hot)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kSvdhrEhdP1"
      },
      "source": [
        "###Haciendo mini-batches para entrenamiento\n",
        "Para entrenar esta data, vamos a crear mini-batches para el entrenamiento. Debemos tener en cuenta que nuestro batch debe tener múltiples secuencias de una cantidad de números.\n",
        "\n",
        "###Creando batches\n",
        "1. Primero vamos a tener que descartar algo de texto, para tener un batch completo.\n",
        "2. Luego camos a dividir nuestro *arr* en N batches.\n",
        "3. Ahora vamos a tener nuestro arreglo, podemos iterar por nuestros mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTLZ6-8Egl5_"
      },
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "    '''Creamos un generador que regresa el batches del tamaño\n",
        "     (batch_size) x (seq_length del arr).\n",
        "       \n",
        "       Argumentos\n",
        "       ---------\n",
        "       arr: Arreglo que queremos crear batchs de el\n",
        "       batch_size: Tamaño del Batch, el número de secuencia por batch\n",
        "       seq_length: Número de caracteres en la secuencia\n",
        "    '''\n",
        "    \n",
        "    batch_size_total = batch_size * seq_length\n",
        "    # Número total de batch que podemos hacer\n",
        "    n_batches = len(arr)//batch_size_total\n",
        "    \n",
        "    # Seleccionamos la cantidad de caracteres necesarios para llenar todo el batch\n",
        "    arr = arr[:n_batches * batch_size_total]\n",
        "    # Reshape en tamaño de columnas batch_size\n",
        "    arr = arr.reshape((batch_size, -1))\n",
        "    \n",
        "    # Iteramos en el arreglo en una secuencia por vez\n",
        "    for n in range(0, arr.shape[1], seq_length):\n",
        "        # Las características\n",
        "        x = arr[:, n:n+seq_length]\n",
        "        # Los objetivos\n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "        except IndexError:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtLRl7PRxcbZ"
      },
      "source": [
        "<h4>Probemos nuestra implementación<h4>\n",
        "Vamos a crear un tamaño batch de 8 y una secuencia de pasos de 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCcFM7kYxak_"
      },
      "source": [
        "batches = get_batches(encoded, 8, 50)\n",
        "x, y = next(batches)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdIsD81HxriI",
        "outputId": "151bca87-ef29-4039-eae1-0eefffc86a00"
      },
      "source": [
        "# Mostramos las primeras 10 secuencias\n",
        "print('x\\n', x[:10, :10])\n",
        "print('\\ny\\n', y[:10, :10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x\n",
            " [[50  4 58  4 30 48 40 30 15 42]\n",
            " [25 33 40 30 12 47 31 34 42 28]\n",
            " [30  1 47 42 30 53 28  4 53  4]\n",
            " [ 6 28 15 47 11 40 44 13 18  4]\n",
            " [11 34 25 40 25 42 15 30 25 42]\n",
            " [37 30 11 40 30 54 26 28 28 42]\n",
            " [40 58 34 11 34 40 30 48 30 25]\n",
            " [56 30 11 47 22 40 28 13 58 42]]\n",
            "\n",
            "y\n",
            " [[ 4 58  4 30 48 40 30 15 42 30]\n",
            " [33 40 30 12 47 31 34 42 28  4]\n",
            " [ 1 47 42 30 53 28  4 53  4 56]\n",
            " [28 15 47 11 40 44 13 18  4 15]\n",
            " [34 25 40 25 42 15 30 25 42 30]\n",
            " [30 11 40 30 54 26 28 28 42 40]\n",
            " [58 34 11 34 40 30 48 30 25 42]\n",
            " [30 11 47 22 40 28 13 58 42 56]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QUZdK7yx1CA"
      },
      "source": [
        "---\n",
        "## Definamos la red con PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddTEXL3_x644"
      },
      "source": [
        "### Estructura del Modelo\n",
        "\n",
        "En `__init__` usaremos la siguiente estructura:\n",
        "* Crear y almacenar los diccionarios necesarios\n",
        "* Definir la capa LSTM que coge los parametros: input_size (Número de caracteres), hidden layer `n_hidden`, número de capas `n_layers`, la propabilidad de dropout `dropout` y batch_first que será `True`\n",
        "* Definamos la capa de dropout\n",
        "* Definimos una red fully-connected con parametros: tamaño de entrada `n_hidden` y la salida (número de caracateres).\n",
        "* Finalmente inicializamos los pesos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37vkcuAIyCMH"
      },
      "source": [
        "---\n",
        "### LSTM Entradas/Salidas\n",
        "\n",
        "Podemos crear una red [LSTM layer] (https://pytorch.org/docs/stable/nn.html#lstm) así\n",
        "\n",
        "```python\n",
        "self.lstm = nn.LSTM(input_size, n_hidden, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "```\n",
        "\n",
        "Donde `input_size` es el número de caracteres que se espera en la secuencia de entrada y `n_hidden` es el número de unidades de capas ocultas, podemos añadir droput. Finalmente en la función `forward` podemos apilar varias capas usando `.vieq`.\n",
        "Además necesitamos crear un hidden state con ceros así:\n",
        "\n",
        "```python\n",
        "self.init_hidden()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv_S3RJHxtao",
        "outputId": "a254b4d8-8689-4418-b4ce-be6efbaff0ed"
      },
      "source": [
        "# Verificamos GPU\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "    print('Entrenando en GPU!')\n",
        "else: \n",
        "    print('No hay GPU disponible, entrenamiento en CPU; considere hacer n_epochs muy pequeños.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando en GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKpsHtbSyHsM"
      },
      "source": [
        "class CharRNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
        "                               drop_prob=0.5, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.lr = lr\n",
        "        \n",
        "        # Creando el diccionario de caracteres\n",
        "        self.chars = tokens\n",
        "        self.int2char = dict(enumerate(self.chars))\n",
        "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
        "        \n",
        "        ## Definimos la LSTM\n",
        "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        ## Definimos la capa de dropout\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        \n",
        "        ## Definimos la capa densa\n",
        "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
        "      \n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        ''' Forward pass through the network. \n",
        "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
        "                \n",
        "        ## Obtenemos el resultado y el nuevo hidden state\n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        \n",
        "        ## pasamos por el droput\n",
        "        out = self.dropout(r_output)\n",
        "        \n",
        "        # Apilamos las salidas del LSTM\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        \n",
        "        ## Pasamos el resultado del LSTM por la FC\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        # retornamos los resultados\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Iniciamos hidden state '''\n",
        "        # Creamos dos tensores con tamaño n_layers x batch_size x n_hidden,\n",
        "        # E iniciamos con cero\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        \n",
        "        return hidden\n",
        "        "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWfW8LjTyT2p"
      },
      "source": [
        "## Tiempo de entrenar\n",
        "\n",
        "La función de entrenamiento define el número de epochs, learning reate y otros parámetros.\n",
        "Usaremos Adam optimizer y cross-entropy loss porque usamos una clasificación de caracteres.\n",
        "\n",
        "Detalle del entrenamiento: \n",
        ">* Usaremos [`clip_grad_norm_`](https://pytorch.org/docs/stable/_modules/torch/nn/utils/clip_grad.html) para evitar la explosión del gradiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27aPhn1CyMsc"
      },
      "source": [
        "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
        "    ''' Entrenando una red\n",
        "    \n",
        "        Argumento\n",
        "        ---------\n",
        "        \n",
        "        net: Red de caracteres RNN\n",
        "        data: El texto que se va a entrenar la red\n",
        "        epochs: Número de epochs que entrenará\n",
        "        batch_size: Número de mini-batch\n",
        "        seq_length: Número de caracteres por mini-batch\n",
        "        lr: learning rate\n",
        "        clip: gradient clipping\n",
        "        val_frac: Dividir la data para validar\n",
        "        print_every: Imprimir el loss y la validación\n",
        "    \n",
        "    '''\n",
        "    net.train()\n",
        "    \n",
        "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Creamos entrenamiento y validación\n",
        "    val_idx = int(len(data)*(1-val_frac))\n",
        "    data, val_data = data[:val_idx], data[val_idx:]\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    \n",
        "    counter = 0\n",
        "    n_chars = len(net.chars)\n",
        "    for e in range(epochs):\n",
        "        # Iniciamos hidden state\n",
        "        h = net.init_hidden(batch_size)\n",
        "        \n",
        "        for x, y in get_batches(data, batch_size, seq_length):\n",
        "            counter += 1\n",
        "            \n",
        "            # One-hot encode y hacemos tensor\n",
        "            x = one_hot_encode(x, n_chars)\n",
        "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "            \n",
        "            if(train_on_gpu):\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            # Creamos una nueva variable para hidden state\n",
        "            h = tuple([each.data for each in h])\n",
        "\n",
        "            # Enceramos el gradiente\n",
        "            net.zero_grad()\n",
        "            \n",
        "            # Obtenemos las salidas\n",
        "            output, h = net(inputs, h)\n",
        "            \n",
        "            # Calculamos la pérdida y optimizamos\n",
        "            loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
        "            loss.backward()\n",
        "            # `clip_grad_norm` preeve la explosión de gradiente, problema común en RNNs / LSTMs.\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            opt.step()\n",
        "            \n",
        "            # La perdida LOSS\n",
        "            if counter % print_every == 0:\n",
        "                # loss validation \n",
        "                val_h = net.init_hidden(batch_size)\n",
        "                val_losses = []\n",
        "                net.eval()\n",
        "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "                    # One-hot encode y creamos Tensores\n",
        "                    x = one_hot_encode(x, n_chars)\n",
        "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "                    \n",
        "                    # Creamos el hidden state,\n",
        "                    val_h = tuple([each.data for each in val_h])\n",
        "                    \n",
        "                    inputs, targets = x, y\n",
        "                    if(train_on_gpu):\n",
        "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "                    output, val_h = net(inputs, val_h)\n",
        "                    val_loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
        "                \n",
        "                    val_losses.append(val_loss.item())\n",
        "                \n",
        "                net.train() # Regresamos a entrenar\n",
        "                \n",
        "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRI3yyvTyY-f"
      },
      "source": [
        "## Instanciando el modelo\n",
        "\n",
        "Asignnado los hiperparametros a nuesttro modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_G5xTOIyi-4",
        "outputId": "3b5e1d15-3754-4a1a-b16c-b50c1afc132c"
      },
      "source": [
        "# Definamos e imprimimos la red\n",
        "n_hidden=512\n",
        "n_layers=2\n",
        "\n",
        "net = CharRNN(caracteres, n_hidden, n_layers)\n",
        "print(net)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CharRNN(\n",
            "  (lstm): LSTM(59, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=59, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMXWmMPHyXJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc3e1b0-88c6-461a-9649-7a2eb443eb83"
      },
      "source": [
        "batch_size = 128\n",
        "seq_length = 100\n",
        "n_epochs = 30 # Aumentaremos al modelo final\n",
        "\n",
        "# Entrenamos el modelo\n",
        "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/30... Step: 10... Loss: 3.1550... Val Loss: 3.1056\n",
            "Epoch: 1/30... Step: 20... Loss: 3.0803... Val Loss: 3.0514\n",
            "Epoch: 1/30... Step: 30... Loss: 3.0530... Val Loss: 3.0365\n",
            "Epoch: 1/30... Step: 40... Loss: 3.0402... Val Loss: 3.0313\n",
            "Epoch: 2/30... Step: 50... Loss: 3.0405... Val Loss: 3.0288\n",
            "Epoch: 2/30... Step: 60... Loss: 3.0356... Val Loss: 3.0260\n",
            "Epoch: 2/30... Step: 70... Loss: 3.0283... Val Loss: 3.0204\n",
            "Epoch: 2/30... Step: 80... Loss: 3.0176... Val Loss: 3.0019\n",
            "Epoch: 2/30... Step: 90... Loss: 2.9790... Val Loss: 2.9544\n",
            "Epoch: 3/30... Step: 100... Loss: 2.8776... Val Loss: 2.8542\n",
            "Epoch: 3/30... Step: 110... Loss: 2.7410... Val Loss: 2.6933\n",
            "Epoch: 3/30... Step: 120... Loss: 2.6954... Val Loss: 2.6504\n",
            "Epoch: 3/30... Step: 130... Loss: 2.5883... Val Loss: 2.5383\n",
            "Epoch: 3/30... Step: 140... Loss: 2.4930... Val Loss: 2.4511\n",
            "Epoch: 4/30... Step: 150... Loss: 2.4127... Val Loss: 2.3703\n",
            "Epoch: 4/30... Step: 160... Loss: 2.3422... Val Loss: 2.3328\n",
            "Epoch: 4/30... Step: 170... Loss: 2.2705... Val Loss: 2.2299\n",
            "Epoch: 4/30... Step: 180... Loss: 2.1982... Val Loss: 2.1534\n",
            "Epoch: 4/30... Step: 190... Loss: 2.1358... Val Loss: 2.0750\n",
            "Epoch: 5/30... Step: 200... Loss: 2.0689... Val Loss: 2.0015\n",
            "Epoch: 5/30... Step: 210... Loss: 2.0235... Val Loss: 1.9376\n",
            "Epoch: 5/30... Step: 220... Loss: 1.9502... Val Loss: 1.8736\n",
            "Epoch: 5/30... Step: 230... Loss: 1.8979... Val Loss: 1.7942\n",
            "Epoch: 5/30... Step: 240... Loss: 1.8648... Val Loss: 1.7190\n",
            "Epoch: 6/30... Step: 250... Loss: 1.7735... Val Loss: 1.6480\n",
            "Epoch: 6/30... Step: 260... Loss: 1.6904... Val Loss: 1.5584\n",
            "Epoch: 6/30... Step: 270... Loss: 1.5915... Val Loss: 1.4641\n",
            "Epoch: 6/30... Step: 280... Loss: 1.5479... Val Loss: 1.3885\n",
            "Epoch: 7/30... Step: 290... Loss: 1.4267... Val Loss: 1.2719\n",
            "Epoch: 7/30... Step: 300... Loss: 1.3420... Val Loss: 1.1902\n",
            "Epoch: 7/30... Step: 310... Loss: 1.2054... Val Loss: 1.0501\n",
            "Epoch: 7/30... Step: 320... Loss: 1.0921... Val Loss: 0.9264\n",
            "Epoch: 7/30... Step: 330... Loss: 1.0028... Val Loss: 0.8184\n",
            "Epoch: 8/30... Step: 340... Loss: 0.8851... Val Loss: 0.7040\n",
            "Epoch: 8/30... Step: 350... Loss: 0.7884... Val Loss: 0.6215\n",
            "Epoch: 8/30... Step: 360... Loss: 0.6917... Val Loss: 0.5088\n",
            "Epoch: 8/30... Step: 370... Loss: 0.5994... Val Loss: 0.4280\n",
            "Epoch: 8/30... Step: 380... Loss: 0.5218... Val Loss: 0.3626\n",
            "Epoch: 9/30... Step: 390... Loss: 0.4523... Val Loss: 0.2967\n",
            "Epoch: 9/30... Step: 400... Loss: 0.3881... Val Loss: 0.2502\n",
            "Epoch: 9/30... Step: 410... Loss: 0.3264... Val Loss: 0.2134\n",
            "Epoch: 9/30... Step: 420... Loss: 0.2759... Val Loss: 0.1839\n",
            "Epoch: 9/30... Step: 430... Loss: 0.2336... Val Loss: 0.1623\n",
            "Epoch: 10/30... Step: 440... Loss: 0.2158... Val Loss: 0.1459\n",
            "Epoch: 10/30... Step: 450... Loss: 0.1745... Val Loss: 0.1351\n",
            "Epoch: 10/30... Step: 460... Loss: 0.1536... Val Loss: 0.1252\n",
            "Epoch: 10/30... Step: 470... Loss: 0.1351... Val Loss: 0.1190\n",
            "Epoch: 10/30... Step: 480... Loss: 0.2123... Val Loss: 0.1164\n",
            "Epoch: 11/30... Step: 490... Loss: 0.1093... Val Loss: 0.1098\n",
            "Epoch: 11/30... Step: 500... Loss: 0.0989... Val Loss: 0.1062\n",
            "Epoch: 11/30... Step: 510... Loss: 0.0895... Val Loss: 0.1049\n",
            "Epoch: 11/30... Step: 520... Loss: 0.0771... Val Loss: 0.1044\n",
            "Epoch: 12/30... Step: 530... Loss: 0.0753... Val Loss: 0.1021\n",
            "Epoch: 12/30... Step: 540... Loss: 0.0696... Val Loss: 0.1008\n",
            "Epoch: 12/30... Step: 550... Loss: 0.0597... Val Loss: 0.0999\n",
            "Epoch: 12/30... Step: 560... Loss: 0.0535... Val Loss: 0.0998\n",
            "Epoch: 12/30... Step: 570... Loss: 0.0497... Val Loss: 0.1005\n",
            "Epoch: 13/30... Step: 580... Loss: 0.0494... Val Loss: 0.0978\n",
            "Epoch: 13/30... Step: 590... Loss: 0.0443... Val Loss: 0.0977\n",
            "Epoch: 13/30... Step: 600... Loss: 0.0391... Val Loss: 0.0985\n",
            "Epoch: 13/30... Step: 610... Loss: 0.0372... Val Loss: 0.0982\n",
            "Epoch: 13/30... Step: 620... Loss: 0.0323... Val Loss: 0.0988\n",
            "Epoch: 14/30... Step: 630... Loss: 0.0363... Val Loss: 0.0963\n",
            "Epoch: 14/30... Step: 640... Loss: 0.0312... Val Loss: 0.0965\n",
            "Epoch: 14/30... Step: 650... Loss: 0.0304... Val Loss: 0.0972\n",
            "Epoch: 14/30... Step: 660... Loss: 0.0271... Val Loss: 0.0982\n",
            "Epoch: 14/30... Step: 670... Loss: 0.0267... Val Loss: 0.0981\n",
            "Epoch: 15/30... Step: 680... Loss: 0.0267... Val Loss: 0.0971\n",
            "Epoch: 15/30... Step: 690... Loss: 0.0244... Val Loss: 0.0971\n",
            "Epoch: 15/30... Step: 700... Loss: 0.0230... Val Loss: 0.0976\n",
            "Epoch: 15/30... Step: 710... Loss: 0.0220... Val Loss: 0.0985\n",
            "Epoch: 15/30... Step: 720... Loss: 0.1395... Val Loss: 0.0978\n",
            "Epoch: 16/30... Step: 730... Loss: 0.0214... Val Loss: 0.0965\n",
            "Epoch: 16/30... Step: 740... Loss: 0.0195... Val Loss: 0.0979\n",
            "Epoch: 16/30... Step: 750... Loss: 0.0193... Val Loss: 0.0982\n",
            "Epoch: 16/30... Step: 760... Loss: 0.0174... Val Loss: 0.0988\n",
            "Epoch: 17/30... Step: 770... Loss: 0.0192... Val Loss: 0.0969\n",
            "Epoch: 17/30... Step: 780... Loss: 0.0181... Val Loss: 0.0966\n",
            "Epoch: 17/30... Step: 790... Loss: 0.0164... Val Loss: 0.0968\n",
            "Epoch: 17/30... Step: 800... Loss: 0.0151... Val Loss: 0.0969\n",
            "Epoch: 17/30... Step: 810... Loss: 0.0139... Val Loss: 0.0975\n",
            "Epoch: 18/30... Step: 820... Loss: 0.0167... Val Loss: 0.0980\n",
            "Epoch: 18/30... Step: 830... Loss: 0.0153... Val Loss: 0.0995\n",
            "Epoch: 18/30... Step: 840... Loss: 0.0134... Val Loss: 0.1013\n",
            "Epoch: 18/30... Step: 850... Loss: 0.0131... Val Loss: 0.1010\n",
            "Epoch: 18/30... Step: 860... Loss: 0.0119... Val Loss: 0.1016\n",
            "Epoch: 19/30... Step: 870... Loss: 0.0177... Val Loss: 0.0979\n",
            "Epoch: 19/30... Step: 880... Loss: 0.0135... Val Loss: 0.0963\n",
            "Epoch: 19/30... Step: 890... Loss: 0.0121... Val Loss: 0.0979\n",
            "Epoch: 19/30... Step: 900... Loss: 0.0108... Val Loss: 0.0976\n",
            "Epoch: 19/30... Step: 910... Loss: 0.0096... Val Loss: 0.0986\n",
            "Epoch: 20/30... Step: 920... Loss: 0.0120... Val Loss: 0.0996\n",
            "Epoch: 20/30... Step: 930... Loss: 0.0111... Val Loss: 0.1025\n",
            "Epoch: 20/30... Step: 940... Loss: 0.0097... Val Loss: 0.1031\n",
            "Epoch: 20/30... Step: 950... Loss: 0.0088... Val Loss: 0.1035\n",
            "Epoch: 20/30... Step: 960... Loss: 0.1338... Val Loss: 0.1031\n",
            "Epoch: 21/30... Step: 970... Loss: 0.0111... Val Loss: 0.0969\n",
            "Epoch: 21/30... Step: 980... Loss: 0.0107... Val Loss: 0.0974\n",
            "Epoch: 21/30... Step: 990... Loss: 0.0085... Val Loss: 0.0978\n",
            "Epoch: 21/30... Step: 1000... Loss: 0.0089... Val Loss: 0.0986\n",
            "Epoch: 22/30... Step: 1010... Loss: 0.0085... Val Loss: 0.0989\n",
            "Epoch: 22/30... Step: 1020... Loss: 0.0091... Val Loss: 0.0997\n",
            "Epoch: 22/30... Step: 1030... Loss: 0.0077... Val Loss: 0.1009\n",
            "Epoch: 22/30... Step: 1040... Loss: 0.0076... Val Loss: 0.1014\n",
            "Epoch: 22/30... Step: 1050... Loss: 0.0074... Val Loss: 0.1017\n",
            "Epoch: 23/30... Step: 1060... Loss: 0.0104... Val Loss: 0.0973\n",
            "Epoch: 23/30... Step: 1070... Loss: 0.0078... Val Loss: 0.0978\n",
            "Epoch: 23/30... Step: 1080... Loss: 0.0075... Val Loss: 0.0984\n",
            "Epoch: 23/30... Step: 1090... Loss: 0.0068... Val Loss: 0.0984\n",
            "Epoch: 23/30... Step: 1100... Loss: 0.0065... Val Loss: 0.0990\n",
            "Epoch: 24/30... Step: 1110... Loss: 0.0085... Val Loss: 0.1012\n",
            "Epoch: 24/30... Step: 1120... Loss: 0.0072... Val Loss: 0.1025\n",
            "Epoch: 24/30... Step: 1130... Loss: 0.0063... Val Loss: 0.1030\n",
            "Epoch: 24/30... Step: 1140... Loss: 0.0060... Val Loss: 0.1038\n",
            "Epoch: 24/30... Step: 1150... Loss: 0.0051... Val Loss: 0.1041\n",
            "Epoch: 25/30... Step: 1160... Loss: 0.0094... Val Loss: 0.0996\n",
            "Epoch: 25/30... Step: 1170... Loss: 0.0073... Val Loss: 0.0985\n",
            "Epoch: 25/30... Step: 1180... Loss: 0.0062... Val Loss: 0.0995\n",
            "Epoch: 25/30... Step: 1190... Loss: 0.0061... Val Loss: 0.0996\n",
            "Epoch: 25/30... Step: 1200... Loss: 0.1236... Val Loss: 0.0990\n",
            "Epoch: 26/30... Step: 1210... Loss: 0.0069... Val Loss: 0.1019\n",
            "Epoch: 26/30... Step: 1220... Loss: 0.0062... Val Loss: 0.1030\n",
            "Epoch: 26/30... Step: 1230... Loss: 0.0053... Val Loss: 0.1030\n",
            "Epoch: 26/30... Step: 1240... Loss: 0.0054... Val Loss: 0.1030\n",
            "Epoch: 27/30... Step: 1250... Loss: 0.0055... Val Loss: 0.0998\n",
            "Epoch: 27/30... Step: 1260... Loss: 0.0061... Val Loss: 0.0994\n",
            "Epoch: 27/30... Step: 1270... Loss: 0.0048... Val Loss: 0.1001\n",
            "Epoch: 27/30... Step: 1280... Loss: 0.0049... Val Loss: 0.1009\n",
            "Epoch: 27/30... Step: 1290... Loss: 0.0046... Val Loss: 0.1011\n",
            "Epoch: 28/30... Step: 1300... Loss: 0.0076... Val Loss: 0.1018\n",
            "Epoch: 28/30... Step: 1310... Loss: 0.0060... Val Loss: 0.1039\n",
            "Epoch: 28/30... Step: 1320... Loss: 0.0049... Val Loss: 0.1040\n",
            "Epoch: 28/30... Step: 1330... Loss: 0.0049... Val Loss: 0.1054\n",
            "Epoch: 28/30... Step: 1340... Loss: 0.0041... Val Loss: 0.1044\n",
            "Epoch: 29/30... Step: 1350... Loss: 0.0055... Val Loss: 0.1018\n",
            "Epoch: 29/30... Step: 1360... Loss: 0.0053... Val Loss: 0.1015\n",
            "Epoch: 29/30... Step: 1370... Loss: 0.0052... Val Loss: 0.1020\n",
            "Epoch: 29/30... Step: 1380... Loss: 0.0042... Val Loss: 0.1022\n",
            "Epoch: 29/30... Step: 1390... Loss: 0.0036... Val Loss: 0.1029\n",
            "Epoch: 30/30... Step: 1400... Loss: 0.0057... Val Loss: 0.1001\n",
            "Epoch: 30/30... Step: 1410... Loss: 0.0054... Val Loss: 0.1014\n",
            "Epoch: 30/30... Step: 1420... Loss: 0.0043... Val Loss: 0.1025\n",
            "Epoch: 30/30... Step: 1430... Loss: 0.0038... Val Loss: 0.1029\n",
            "Epoch: 30/30... Step: 1440... Loss: 0.1166... Val Loss: 0.1027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK2LpWB24GWm"
      },
      "source": [
        "## Checkpoint\n",
        "\n",
        "Después de entrenar debemos guardar nuestro modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac9AvZSEycou"
      },
      "source": [
        "# Ponemos un nombre y guardamos\n",
        "nombre_modelo = 'rnn_lsmt.net'\n",
        "\n",
        "checkpoint = {'n_hidden': net.n_hidden,\n",
        "              'n_layers': net.n_layers,\n",
        "              'state_dict': net.state_dict(),\n",
        "              'tokens': net.chars}\n",
        "\n",
        "with open(nombre_modelo, 'wb') as f:\n",
        "    torch.save(checkpoint, f)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-qDQWSb4LeF"
      },
      "source": [
        "---\n",
        "## Haciendo predicciones\n",
        "\n",
        "¡Ahora que el modelo está entrenado, querremos probarlo y hacer predicciones sobre los próximos personajes! Para muestrear, pasamos un carácter y hacemos que la red prediga el siguiente carácter. Luego tomamos ese personaje, lo devolvemos y obtenemos otro personaje predicho. ¡Sigue haciendo esto y generarás un montón de texto!\n",
        "\n",
        "### Nota sobre la función `predict`\n",
        "\n",
        "La salida de nuestro RNN es de una capa completamente conectada y genera una **distribution of next-character scores**.\n",
        "\n",
        "> Para obtener el siguiente carácter, aplicamos una función softmax, que nos da una distribución de *probabilidad* que luego podemos muestrear para predecir el siguiente carácter.\n",
        "\n",
        "### Top K\n",
        "Nuestro modelo usa una softmax, pero podemos añadir algo de aleatoridad para escoger uno de los caracteres más probables con Top K, asi puede generar un texto algo aleatorio y aveces absurdo. [topk, here](https://pytorch.org/docs/stable/torch.html#torch.topk).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgCpOGgP4IzK"
      },
      "source": [
        "def predict(net, char, h=None, top_k=None):\n",
        "        ''' damos un caracter y predice el siguiente\n",
        "            Regresa la predcción y el hidden state\n",
        "        '''\n",
        "        \n",
        "        # Entrada de tensores\n",
        "        x = np.array([[net.char2int[char]]])\n",
        "        x = one_hot_encode(x, len(net.chars))\n",
        "        inputs = torch.from_numpy(x)\n",
        "        \n",
        "        if(train_on_gpu):\n",
        "            inputs = inputs.cuda()\n",
        "        \n",
        "        # Quitar el hidden state del historial\n",
        "        h = tuple([each.data for each in h])\n",
        "        # Obtenemos la salida del modelo\n",
        "        out, h = net(inputs, h)\n",
        "\n",
        "        # Obtenemos la probabildad de caracteres\n",
        "        p = F.softmax(out, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu() # Regresa a la CPU\n",
        "        \n",
        "        # Obtenemos el top de caracteres\n",
        "        if top_k is None:\n",
        "            top_ch = np.arange(len(net.chars))\n",
        "        else:\n",
        "            p, top_ch = p.topk(top_k)\n",
        "            top_ch = top_ch.numpy().squeeze()\n",
        "        \n",
        "        # añadimos algo de aleatoridad al siguiente caracter\n",
        "        p = p.numpy().squeeze()\n",
        "        char = np.random.choice(top_ch, p=p/p.sum())\n",
        "        \n",
        "        # Devolvemos el hidden state y el caracter\n",
        "        return net.int2char[char], h"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NllnT734RAC"
      },
      "source": [
        "### Generando texto\n",
        "\n",
        "Al incio será más aleatorio, mientras más tiempo pase por la red más robusta será la predicción.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXRuWZeF4OHF"
      },
      "source": [
        "def sample(net, size, prime='The', top_k=None):\n",
        "        \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    else:\n",
        "        net.cpu()\n",
        "    \n",
        "    net.eval() # Evalua modelo\n",
        "    \n",
        "    # Los primeros caracteres\n",
        "    chars = [ch for ch in prime]\n",
        "    h = net.init_hidden(1)\n",
        "    for ch in prime:\n",
        "        char, h = predict(net, ch, h, top_k=top_k)\n",
        "\n",
        "    chars.append(char)\n",
        "    \n",
        "    # Pasamos el caracter anterior y genera el siguiente\n",
        "    for ii in range(size):\n",
        "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJtnOPsn4Sdv",
        "outputId": "ababde28-e824-496b-cf5a-048f70541c7d"
      },
      "source": [
        "print(sample(net, 1000, prime='El libro empieza años', top_k=5))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El libro empieza años después de la fundación, en la época en que José Arcadio Buendía parecía haber superado ya su antigua obsesión por los\n",
            "grandes inventos que traían a Macondo los gitanos de la tribu de Melquíades, artilugios sobradamente conocidos (como los imanes o el catalejo)\n",
            "que no habían llegado todavía a aquella recóndita aldea. Deseoso de poner en contacto el pueblo con los avances de la civilización e ignorando\n",
            "completamente la geografía de la región, José Arcadio Buendía había emprendido una fracasada expedición al Norte: encontraron únicamente tierras\n",
            "inhóspitas y, a continuación, los restos de un galeón español y el mar; seguidamente, su proyecto de trasladar Macondo a algún lugar\n",
            "menos aislado topó la férrea oposición de Úrsula.\n",
            "Los primeros Buendía tuvieron tres hijos (José Arcadio, Aureliano y Amaranta), cuya infancia, adolescencia y\n",
            "primera juventud se relata en esta primera parte. El mayor, llamado José Arcadio como su padre, nació durante\n",
            "el viaje fundacional. Ya en la adolescencia, el \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNIUyIH07a71"
      },
      "source": [
        "Como ya tenemos el modelo guardado en **rnn_lsmt.net** podemos hacer el uso de ello para generar textos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQj50l6z4i31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f6ca1d-2d5b-4716-b8e4-66d7703536aa"
      },
      "source": [
        "# Cargamos el modelo\n",
        "with open('rnn_lsmt.net', 'rb') as f:\n",
        "    checkpoint = torch.load(f)\n",
        "    \n",
        "loaded = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
        "loaded.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT_syiLa7dP9",
        "outputId": "b74af629-c6c0-4956-b024-53f23dc11627"
      },
      "source": [
        "# Creamos nuevo texto con un texto inicial\n",
        "print(sample(loaded, 1000, top_k=5, prime=\"El narrador se remonta\"))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El narrador se remonta noca menos que al siglo XVI para presentarnos a los bisabuelos de los protagonistas,\n",
            "pero la historia comienza Varios siglos más tarde, con la boda de los futuros fundadores de Macondo,\n",
            "que eran primos entre sí: José Arcadio Buendía y Úrsula Iguarán.\n",
            "Con nefastos augurios sobre su descendencia por su cercano parentesco\n",
            "(unos tíos de los recién casados habían tenido un hijo con cola de cerdo),\n",
            "la madre de Úrsula logró aterrorizar a su hija; enfundada en un inquebrantable cinturón de castidad,\n",
            "y pese a las embestidas de José Arcadio, Úrsula impidió durante un año y medio la consumación del matrimonio.\n",
            "Las habladurías atribuían la falta de hijos a la impotencia de José Arcadio, y un día Prudencio Aguilar,\n",
            "después de perder una riña de gallos, se burló públicamente de su poca hombría. Tal ofensa da lugar\n",
            "a un duelo de honor en que Prudencio Aguilar muere a manos de José Arcadio, quien obliga a continuación a su esposa a quitarse el cinturón.\n",
            "Con la consumación del matrimonio todo pareció v\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9A78nng7jji"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}